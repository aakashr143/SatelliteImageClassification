{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98110bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "import seaborn as sn\n",
    "from torchcam.methods import CAM, GradCAM\n",
    "from torchcam.utils import overlay_mask\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from LandUseDataset import LandUseDataset, Mode\n",
    "from Models import LandUseModelResnet50\n",
    "from Models import LandUseModelResnet50NoFeatures, LandUseModelResnet152NoFeatures, LandUseModelVisionTransformerB16NoFeatures, LandUseModelDensenet161NoFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d1733",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "transform = {\n",
    "    \"validation\": transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \"reverse\": transforms.ToPILImage()\n",
    "}\n",
    "\n",
    "dataset = LandUseDataset(Mode.EXTERNAL, transform=transform[\"validation\"], image_size=IMAGE_SIZE)\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=os.cpu_count())\n",
    "\n",
    "test_dataset = LandUseDataset(Mode.TEST, transform=transform[\"validation\"], image_size=IMAGE_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd4fa76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LandUseModelVisionTransformerB16NoFeatures(len(dataset.classes), DEVICE).to(DEVICE)\n",
    "\n",
    "checkpoint = torch.load(r\"C:\\Users\\aakas\\Documents\\MLDL Project\\Project\\Checkpoints\\visiontransformerb16_nofeatures\\2024-02-11 20_30_58\\model_visiontransformerb16_nofeatures_last_48.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93f30c1",
   "metadata": {},
   "source": [
    "Accuracy on the test and external dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab2c3c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load = loader\n",
    "ds = dataset\n",
    "\n",
    "correct = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X, y in tqdm(load):\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        pred = model(X).argmax(dim=1).item()\n",
    "\n",
    "        if pred == y.item():\n",
    "            correct += 1\n",
    "\n",
    "print(\"External\")\n",
    "print(100 * correct / len(ds))\n",
    "\n",
    "load = test_loader\n",
    "ds = test_dataset\n",
    "\n",
    "correct = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X, y in tqdm(load):\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        pred = model(X).argmax(dim=1).item()\n",
    "\n",
    "        if pred == y.item():\n",
    "            correct += 1\n",
    "            \n",
    "print(\"test\")      \n",
    "print(100 * correct / len(ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c80eb30",
   "metadata": {},
   "source": [
    "Get misclassified images on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495390c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "load = test_loader\n",
    "ds = test_dataset\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (X, y) in enumerate(tqdm(load)):\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        pred = model(X)\n",
    "        \n",
    "        if pred.argmax(dim=1).item() != y.item():\n",
    "            pred_class = \"\"\n",
    "            target_class = \"\"\n",
    "\n",
    "            for k, v in test_dataset.classes.items():\n",
    "                if v == y.item():\n",
    "                    target_class = k\n",
    "                if v == pred.argmax(dim=1).item():\n",
    "                    pred_class = k\n",
    "            \n",
    "            fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "            ax.imshow(to_pil_image(X[0]))\n",
    "            ax.axis(\"off\")\n",
    "            fig.suptitle(f'Target: {target_class} ({100 * pred[0][y].item():.3f}%)\\nPred: {pred_class} ({100 * pred[0][pred.argmax(dim=1).item()]:.3f}%)', fontsize=12)\n",
    "            plt.show()\n",
    "            fig.savefig(f\"Misclassified/{model.name}_{i}.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d40b4a",
   "metadata": {},
   "source": [
    "Get activation map for misclassified images on the test dataset, when using the 2% range method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfd72ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load = test_loader\n",
    "ds = test_dataset\n",
    "\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "incorrect_same = 0\n",
    "y_target = []\n",
    "y_pred = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for params in model.parameters():\n",
    "    params.requires_grad = True\n",
    "    \n",
    "#cam_extractor = CAM(model, target_layer=\"base_model.layer4\", fc_layer=\"classifier.1\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (X, y) in enumerate(load):\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        pred = model(X)\n",
    "\n",
    "        if pred.argmax(dim=1).item() != y.item():\n",
    "            incorrect += 1\n",
    "            \n",
    "            pred_prob = 100 * pred[0][y].item()\n",
    "            target_prob = 100 * pred[0][pred.argmax(dim=1).item()].item()\n",
    "            \n",
    "            if pred_prob - 2 < target_prob < pred_prob + 2:\n",
    "                incorrect_same += 1\n",
    "                y_target.append(y.item())\n",
    "                y_pred.append(y.item())\n",
    "            else:\n",
    "                y_target.append(y.item())\n",
    "                y_pred.append(pred.argmax(dim=1).item())\n",
    "\n",
    "            \n",
    "            pred_class = \"\"\n",
    "            target_class = \"\"\n",
    "\n",
    "            for k, v in test_dataset.classes.items():\n",
    "                if v == y.item():\n",
    "                    target_class = k\n",
    "                if v == pred.argmax(dim=1).item():\n",
    "                    pred_class = k\n",
    "                    \n",
    "            \n",
    "            \"\"\"\n",
    "            activation_map = cam_extractor(pred.argmax(dim=1).item(), pred)\n",
    "            result = overlay_mask(to_pil_image(X[0]), to_pil_image(activation_map[0].squeeze(0), mode=\"F\"),  alpha=0.5)\n",
    "\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "            fig.suptitle(f'Target: {target_class} ({100 * pred[0][y].item():.3f}%)\\nPred: {pred_class} ({100 * pred[0][pred.argmax(dim=1).item()]:.3f}%)', fontsize=12)\n",
    "\n",
    "            ax[0].imshow(to_pil_image(X[0]))\n",
    "            ax[1].imshow(result)\n",
    "\n",
    "            ax[0].axis('off')\n",
    "            ax[1].axis('off')\n",
    "\n",
    "            plt.show()\n",
    "            \n",
    "            fig.savefig(f\"CAM IMAGES/{model.name}_{i}.svg\")\n",
    "            \"\"\"\n",
    "            \n",
    "        else:\n",
    "            correct += 1\n",
    "            y_target.append(y.item())\n",
    "            y_pred.append(pred.argmax(dim=1).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639ae5af",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78541f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {100 * correct / len(ds)}\")\n",
    "print(f\"AccuracyNew: {100 * (correct + incorrect_same) / len(ds)}\")\n",
    "print(f\"Incorrect: {100 * incorrect / len(ds)}\")\n",
    "print(f\"Incorrect with same prob: {100 * incorrect_same / incorrect}\")\n",
    "print(incorrect, incorrect_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb064e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(test_dataset.classes.keys())\n",
    "\n",
    "y_pred_labels = [labels[i] for i in y_pred]\n",
    "y_target_labels = [labels[i] for i in y_target]\n",
    "\n",
    "data = precision_recall_fscore_support(y_target_labels, y_pred_labels, average=None, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc863311",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in data:\n",
    "    s = sum(item) / 33\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68434a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = confusion_matrix(y_true=y_target, y_pred=y_pred)\n",
    "df_cm = pd.DataFrame(cf, index=[labels], columns=[labels])\n",
    "plt.figure(figsize=(15,15))\n",
    "ax = sn.heatmap(df_cm, annot=True, vmax=30)\n",
    "ax.set(xlabel=\"Pred\", ylabel=\"Target\")\n",
    "plt.savefig(\"fc_nofeatures_acc2.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b5f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
